{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f378d4c1",
   "metadata": {},
   "source": [
    "# Parallelism in Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953cf720",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a84231",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab52d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1793f3d7",
   "metadata": {},
   "source": [
    "### Setup Data paths for Caltech101 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec2263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"../data\")\n",
    "ARCHIVE_URL = \"https://www.kaggle.com/api/v1/datasets/download/imbikramsaha/caltech-101\"\n",
    "ARCHIVE_PATH = DATA_ROOT / \"caltech101.zip\"\n",
    "EXTRACT_DIR = DATA_ROOT / \"caltech-101\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7715e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_it(func):\n",
    "    \"\"\"Decorator to measure execution time of functions.\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"{func.__name__} took {end - start:.4f}s\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd2596",
   "metadata": {},
   "source": [
    "### Download Caltech101 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0e2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Caltech101 archive...\n",
      "Extracting Caltech101 archive...\n",
      "Caltech101 dataset extracted to ../data/caltech101\n"
     ]
    }
   ],
   "source": [
    "def ensure_caltech101():\n",
    "    if EXTRACT_DIR.exists() and any(EXTRACT_DIR.iterdir()):\n",
    "        print(\"Caltech101 dataset already exists.\")\n",
    "        return\n",
    "    print(\"Downloading Caltech101 archive...\")\n",
    "    urllib.request.urlretrieve(ARCHIVE_URL, ARCHIVE_PATH)\n",
    "    print(\"Extracting Caltech101 archive...\")\n",
    "    with zipfile.ZipFile(ARCHIVE_PATH, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(path=DATA_ROOT)\n",
    "    print(\"Caltech101 dataset extracted to\", EXTRACT_DIR)\n",
    "\n",
    "ensure_caltech101()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e3faf",
   "metadata": {},
   "source": [
    "### Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85575038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,\n",
       " [PosixPath('../data/caltech-101/yin_yang/image_0042.jpg'),\n",
       "  PosixPath('../data/caltech-101/yin_yang/image_0002.jpg'),\n",
       "  PosixPath('../data/caltech-101/yin_yang/image_0053.jpg'),\n",
       "  PosixPath('../data/caltech-101/yin_yang/image_0009.jpg'),\n",
       "  PosixPath('../data/caltech-101/yin_yang/image_0019.jpg')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_images(root: Path, limit: int=500) -> List[Path]:\n",
    "    extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "    paths = [path for path in root.rglob(\"*\") if path.suffix.lower() in extensions]\n",
    "    return paths[:limit]\n",
    "\n",
    "paths = sample_images(EXTRACT_DIR)\n",
    "len(paths), paths[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977414f",
   "metadata": {},
   "source": [
    "## Serial Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec50a14",
   "metadata": {},
   "source": [
    "### Resize, grayscale, Sobel edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3128fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resize(path, size=(224,224)):\n",
    "    \"\"\"\n",
    "    Open an image, convert it to RGB to ensure we have 3 channels, and resize it.\n",
    "    Returns a NumPy array of shape (height, width, 3).\n",
    "    \"\"\"\n",
    "    with Image.open(path) as img:\n",
    "        img = img.convert(\"RGB\").resize(size, Image.BILINEAR)\n",
    "        return np.array(img, dtype=np.uint8)\n",
    "\n",
    "def to_gray(img_rgb):\n",
    "    \"\"\"\n",
    "    Convert an RGB image to grayscale using perceptual weights.\n",
    "    Returns a NumPy array of shape (height, width).\n",
    "    \"\"\"\n",
    "    # Use ellipsis (...) to select all pixels\n",
    "    r, g, b = img_rgb[..., 0], img_rgb[..., 1], img_rgb[..., 2]\n",
    "    # Apply ITU-R 601 to calculate luminance\n",
    "    # Cast float32 to avoid overflow later\n",
    "    return (0.299 * r + 0.587 * g + 0.114 * b).astype(np.float32)\n",
    "\n",
    "def sobel_edges(img_gray):\n",
    "    \"\"\"\n",
    "    Apply the Sobel operator to a grayscale image of shape (height, width) to detect edges.\n",
    "    Returns a NumPy array of the same shape as the input image.\n",
    "    \"\"\"\n",
    "    # Create two 3x3 Sobel kernels\n",
    "    sobel_x = np.array([[-1, 0, 1],\n",
    "                        [-2, 0, 2],\n",
    "                        [-1, 0, 1]], dtype=np.float32)\n",
    "    sobel_y = np.array([[ 1, 2, 1],\n",
    "                        [ 0, 0, 0],\n",
    "                        [-1,-2,-1]], dtype=np.float32)\n",
    "\n",
    "    grad = np.pad(img_gray, ((1, 1), (1, 1)), mode='edge')\n",
    "    grad_x = (\n",
    "        grad[:-2, :-2] * sobel_x[0, 0] + grad[:-2, 1:-1] * sobel_x[0, 1] + grad[:-2, 2:] * sobel_x[0, 2] +\n",
    "        grad[1:-1, :-2] * sobel_x[1, 0] + grad[1:-1, 1:-1] * sobel_x[1, 1] + grad[1:-1, 2:] * sobel_x[1, 2] +\n",
    "        grad[2:, :-2] * sobel_x[2, 0] + grad[2:, 1:-1] * sobel_x[2, 1] + grad[2:, 2:] * sobel_x[2, 2]\n",
    "    )\n",
    "    grad_y = (\n",
    "        grad[:-2, :-2] * sobel_y[0, 0] + grad[:-2, 1:-1] * sobel_y[0, 1] + grad[:-2, 2:] * sobel_y[0, 2] +\n",
    "        grad[1:-1, :-2] * sobel_y[1, 0] + grad[1:-1, 1:-1] * sobel_y[1, 1] + grad[1:-1, 2:] * sobel_y[1, 2] +\n",
    "        grad[2:, :-2] * sobel_y[2, 0] + grad[2:, 1:-1] * sobel_y[2, 1] + grad[2:, 2:] * sobel_y[2, 2]\n",
    "    )\n",
    "    return np.sqrt(grad_x**2 + grad_y**2).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc1d0cf",
   "metadata": {},
   "source": [
    "### Serial Preprocessing (full dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563a4ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_one(path, size=(224, 224), bins=32):\n",
    "    \"\"\"\n",
    "    Preprocess pipeline for one image.\n",
    "    Returns a dictionary containing components for reuse.\n",
    "    \"\"\"\n",
    "    img_resized = load_resize(path, size)\n",
    "    img_gray = to_gray(img_resized)\n",
    "    img_edges = sobel_edges(img_gray)\n",
    "\n",
    "    hists = []\n",
    "    for channel in range(3):\n",
    "        hist_channel, _ = np.histogram(img_resized[..., channel], bins=bins, range=(0, 255))\n",
    "        hists.append(hist_channel.astype(np.float32))\n",
    "\n",
    "    color_hist = np.concatenate(hists, axis=0)\n",
    "\n",
    "    return {\n",
    "        \"path\": str(path),\n",
    "        \"resized\": img_resized,\n",
    "        \"gray\": img_gray,\n",
    "        \"edges\": img_edges,\n",
    "        \"color_hist\": color_hist,\n",
    "        \"size\": size,\n",
    "        \"bins\": bins\n",
    "    }\n",
    "\n",
    "def preprocess_all_serial(image_paths, size=(224, 224), bins=32, limit=None):\n",
    "    \"\"\"\n",
    "    Preprocess pipeline for a list of images.\n",
    "    Returns a list of dictionaries, each containing components for reuse.\n",
    "    \"\"\"\n",
    "    if limit is not None:\n",
    "        image_paths = image_paths[:limit]\n",
    "    return [preprocess_one(path, size=size, bins=bins) for path in image_paths]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6361d37c",
   "metadata": {},
   "source": [
    "### Serial Preprocessing (minimal dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_one_min(path, size=(224,224), bins=32):\n",
    "    img = load_resize(path, size)\n",
    "    gray = to_gray(img)\n",
    "    edges = sobel_edges(gray)\n",
    "    # Simple feature: edge mean + color hist (density)\n",
    "    hists = []\n",
    "    for c in range(3):\n",
    "        h, _ = np.histogram(img[..., c], bins=bins, range=(0,255), density=True)\n",
    "        hists.append(h.astype(np.float32))\n",
    "    color_hist = np.concatenate(hists)\n",
    "    return {\n",
    "        \"path\": str(path),\n",
    "        \"edge_mean\": float(edges.mean()),\n",
    "        \"edge_max\": float(edges.max()),\n",
    "        \"color_hist\": color_hist\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f2e77",
   "metadata": {},
   "source": [
    "### Performance test on different image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e65219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, statistics as stats\n",
    "\n",
    "def measure_components(paths, limit=60, size=(224,224)):\n",
    "    t_load = []\n",
    "    t_compute = []\n",
    "    for p in paths[:limit]:\n",
    "        t0 = time.perf_counter()\n",
    "        img = load_resize(p, size=size)\n",
    "        t1 = time.perf_counter()\n",
    "        gray = to_gray(img)\n",
    "        edges = sobel_edges(gray)\n",
    "        t2 = time.perf_counter()\n",
    "        t_load.append(t1 - t0)\n",
    "        t_compute.append(t2 - t1)\n",
    "    return {\n",
    "        \"n\": limit,\n",
    "        \"load_mean\": stats.mean(t_load),\n",
    "        \"compute_mean\": stats.mean(t_compute),\n",
    "        \"load_total\": sum(t_load),\n",
    "        \"compute_total\": sum(t_compute)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388b26be",
   "metadata": {},
   "source": [
    "#### 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75ed35c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 80,\n",
       " 'load_mean': 0.001820724237950344,\n",
       " 'compute_mean': 0.0012321253870140937,\n",
       " 'load_total': 0.14565793903602753,\n",
       " 'compute_total': 0.09857003096112749}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "component_stats_224 = measure_components(paths, limit=80, size=(224,224))\n",
    "component_stats_224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f7ba7",
   "metadata": {},
   "source": [
    "#### 112x112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55be4fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 80,\n",
       " 'load_mean': 0.0013956687629615772,\n",
       " 'compute_mean': 0.0005102350501147157,\n",
       " 'load_total': 0.11165350103692617,\n",
       " 'compute_total': 0.040818804009177256}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "component_stats_112 = measure_components(paths, limit=80, size=(112,112))\n",
    "component_stats_112"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c0d8c",
   "metadata": {},
   "source": [
    "#### 56x56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1783a6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 80,\n",
       " 'load_mean': 0.0012900930746582162,\n",
       " 'compute_mean': 0.00035793070046565847,\n",
       " 'load_total': 0.1032074459726573,\n",
       " 'compute_total': 0.028634456037252676}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "component_stats_56 = measure_components(paths, limit=80, size=(56,56))\n",
    "component_stats_56"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bd354d",
   "metadata": {},
   "source": [
    "## Parallel Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00390dfb",
   "metadata": {},
   "source": [
    "### Parallel Preprocessing (full dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d71b169b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcessPool full objects: 200 images in 1.35s\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import os, math\n",
    "\n",
    "def preprocess_parallel(paths, size=(224,224), bins=32, max_workers=None, limit=None):\n",
    "    if limit: paths = paths[:limit]\n",
    "    t0 = time.perf_counter()\n",
    "    out = []\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futures = [ex.submit(preprocess_one, p, size, bins) for p in paths]\n",
    "        for f in as_completed(futures):\n",
    "            out.append(f.result())\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    return out, elapsed\n",
    "\n",
    "par_samples, par_time = preprocess_parallel(paths, limit=200)\n",
    "print(f\"ProcessPool full objects: {len(par_samples)} images in {par_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc198586",
   "metadata": {},
   "source": [
    "### Parallel Preprocessing (minimal dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0cbf11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcessPool minimal dict: 200 images in 1.20s\n"
     ]
    }
   ],
   "source": [
    "def preprocess_parallel_min(paths, size=(224,224), bins=32, max_workers=None, limit=None):\n",
    "    if limit: paths = paths[:limit]\n",
    "    t0 = time.perf_counter()\n",
    "    out = []\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futures = [ex.submit(preprocess_one_min, p, size, bins) for p in paths]\n",
    "        for f in as_completed(futures):\n",
    "            out.append(f.result())\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    return out, elapsed\n",
    "\n",
    "par_min_samples, par_min_time = preprocess_parallel_min(paths, limit=200)\n",
    "print(f\"ProcessPool minimal dict: {len(par_min_samples)} images in {par_min_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baefa72d",
   "metadata": {},
   "source": [
    "### Preprocessing using threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af707a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThreadPool: 200 images in 2.81s\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def preprocess_threads(paths, size=(224,224), bins=32, limit=None):\n",
    "    if limit: paths = paths[:limit]\n",
    "    t0 = time.perf_counter()\n",
    "    with ThreadPoolExecutor() as ex:\n",
    "        results = list(ex.map(lambda p: preprocess_one(p, size, bins), paths))\n",
    "    return results, time.perf_counter() - t0\n",
    "\n",
    "thr_samples, thr_time = preprocess_threads(paths, limit=200)\n",
    "print(f\"ThreadPool: {len(thr_samples)} images in {thr_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26dd2d",
   "metadata": {},
   "source": [
    "### Evaluating Process Speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78bd1b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial (200 images): 1.22s\n",
      "Speedups vs serial:\n",
      "  Processes (full objects): 0.90x\n",
      "  Processes (minimal dict): 1.02x\n",
      "  Threads: 0.44x\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "serial_subset = preprocess_all_serial(paths[:200])\n",
    "serial_time = time.perf_counter() - t0\n",
    "print(f\"Serial (200 images): {serial_time:.2f}s\")\n",
    "\n",
    "print(f\"Speedups vs serial:\")\n",
    "print(f\"  Processes (full objects): {serial_time / par_time:.2f}x\")\n",
    "print(f\"  Processes (minimal dict): {serial_time / par_min_time:.2f}x\")\n",
    "print(f\"  Threads: {serial_time / thr_time:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-parallelism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
