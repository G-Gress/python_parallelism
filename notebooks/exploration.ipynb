{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f378d4c1",
   "metadata": {},
   "source": [
    "# Parallelism in Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953cf720",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a84231",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab52d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1793f3d7",
   "metadata": {},
   "source": [
    "### Setup Data paths for Caltech101 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec2263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"../data\")\n",
    "ARCHIVE_URL = \"https://www.kaggle.com/api/v1/datasets/download/imbikramsaha/caltech-101\"\n",
    "ARCHIVE_PATH = DATA_ROOT / \"caltech101.zip\"\n",
    "EXTRACT_DIR = DATA_ROOT / \"caltech-101\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7715e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_it(func):\n",
    "    \"\"\"Decorator to measure execution time of functions.\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"{func.__name__} took {end - start:.4f}s\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd2596",
   "metadata": {},
   "source": [
    "### Download Caltech101 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0e2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Caltech101 archive...\n",
      "Extracting Caltech101 archive...\n",
      "Caltech101 dataset extracted to ../data/caltech101\n"
     ]
    }
   ],
   "source": [
    "def ensure_caltech101():\n",
    "    if EXTRACT_DIR.exists() and any(EXTRACT_DIR.iterdir()):\n",
    "        print(\"Caltech101 dataset already exists.\")\n",
    "        return\n",
    "    print(\"Downloading Caltech101 archive...\")\n",
    "    urllib.request.urlretrieve(ARCHIVE_URL, ARCHIVE_PATH)\n",
    "    print(\"Extracting Caltech101 archive...\")\n",
    "    with zipfile.ZipFile(ARCHIVE_PATH, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(path=DATA_ROOT)\n",
    "    print(\"Caltech101 dataset extracted to\", EXTRACT_DIR)\n",
    "\n",
    "ensure_caltech101()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e3faf",
   "metadata": {},
   "source": [
    "### Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85575038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,\n",
       " [PosixPath('../data/caltech-101/yin_yang/image_0042.jpg'),\n",
       "  PosixPath('../data/caltech-101/yin_yang/image_0002.jpg'),\n",
       "  PosixPath('../data/caltech-101/yin_yang/image_0053.jpg'),\n",
       "  PosixPath('../data/caltech-101/yin_yang/image_0009.jpg'),\n",
       "  PosixPath('../data/caltech-101/yin_yang/image_0019.jpg')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_images(root: Path, limit: int=500) -> List[Path]:\n",
    "    extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "    paths = [path for path in root.rglob(\"*\") if path.suffix.lower() in extensions]\n",
    "    return paths[:limit]\n",
    "\n",
    "paths = sample_images(EXTRACT_DIR)\n",
    "len(paths), paths[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977414f",
   "metadata": {},
   "source": [
    "## Serial Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec50a14",
   "metadata": {},
   "source": [
    "Resize, grayscale, Sobel edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3128fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resize(path, size=(224,224)):\n",
    "    \"\"\"\n",
    "    Open an image, convert it to RGB to ensure we have 3 channels, and resize it.\n",
    "    Returns a NumPy array of shape (height, width, 3).\n",
    "    \"\"\"\n",
    "    with Image.open(path) as img:\n",
    "        img = img.convert(\"RGB\").resize(size, Image.BILINEAR)\n",
    "        return np.array(img, dtype=np.uint8)\n",
    "\n",
    "def to_gray(img_rgb):\n",
    "    \"\"\"\n",
    "    Convert an RGB image to grayscale using perceptual weights.\n",
    "    Returns a NumPy array of shape (height, width).\n",
    "    \"\"\"\n",
    "    # Use ellipsis (...) to select all pixels\n",
    "    r, g, b = img_rgb[..., 0], img_rgb[..., 1], img_rgb[..., 2]\n",
    "    # Apply ITU-R 601 to calculate luminance\n",
    "    # Cast float32 to avoid overflow later\n",
    "    return (0.299 * r + 0.587 * g + 0.114 * b).astype(np.float32)\n",
    "\n",
    "def sobel_edges(img_gray):\n",
    "    \"\"\"\n",
    "    Apply the Sobel operator to a grayscale image of shape (height, width) to detect edges.\n",
    "    Returns a NumPy array of the same shape as the input image.\n",
    "    \"\"\"\n",
    "    # Create two 3x3 Sobel kernels\n",
    "    sobel_x = np.array([[-1, 0, 1],\n",
    "                        [-2, 0, 2],\n",
    "                        [-1, 0, 1]], dtype=np.float32)\n",
    "    sobel_y = np.array([[ 1, 2, 1],\n",
    "                        [ 0, 0, 0],\n",
    "                        [-1,-2,-1]], dtype=np.float32)\n",
    "\n",
    "    grad = np.pad(img_gray, ((1, 1), (1, 1)), mode='edge')\n",
    "    grad_x = (\n",
    "        grad[:-2, :-2] * sobel_x[0, 0] + grad[:-2, 1:-1] * sobel_x[0, 1] + grad[:-2, 2:] * sobel_x[0, 2] +\n",
    "        grad[1:-1, :-2] * sobel_x[1, 0] + grad[1:-1, 1:-1] * sobel_x[1, 1] + grad[1:-1, 2:] * sobel_x[1, 2] +\n",
    "        grad[2:, :-2] * sobel_x[2, 0] + grad[2:, 1:-1] * sobel_x[2, 1] + grad[2:, 2:] * sobel_x[2, 2]\n",
    "    )\n",
    "    grad_y = (\n",
    "        grad[:-2, :-2] * sobel_y[0, 0] + grad[:-2, 1:-1] * sobel_y[0, 1] + grad[:-2, 2:] * sobel_y[0, 2] +\n",
    "        grad[1:-1, :-2] * sobel_y[1, 0] + grad[1:-1, 1:-1] * sobel_y[1, 1] + grad[1:-1, 2:] * sobel_y[1, 2] +\n",
    "        grad[2:, :-2] * sobel_y[2, 0] + grad[2:, 1:-1] * sobel_y[2, 1] + grad[2:, 2:] * sobel_y[2, 2]\n",
    "    )\n",
    "    return np.sqrt(grad_x**2 + grad_y**2).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "563a4ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_one(path, size=(224, 224), bins=32):\n",
    "    \"\"\"\n",
    "    Preprocess pipeline for one image.\n",
    "    Returns a dictionary containing components for reuse.\n",
    "    \"\"\"\n",
    "    img_resized = load_resize(path, size)\n",
    "    img_gray = to_gray(img_resized)\n",
    "    img_edges = sobel_edges(img_gray)\n",
    "\n",
    "    hists = []\n",
    "    for channel in range(3):\n",
    "        hist_channel, _ = np.histogram(img_resized[..., channel], bins=bins, range=(0, 255))\n",
    "        hists.append(hist_channel.astype(np.float32))\n",
    "\n",
    "    color_hist = np.concatenate(hists, axis=0)\n",
    "\n",
    "    return {\n",
    "        \"path\": str(path),\n",
    "        \"resized\": img_resized,\n",
    "        \"gray\": img_gray,\n",
    "        \"edges\": img_edges,\n",
    "        \"color_hist\": color_hist,\n",
    "        \"size\": size,\n",
    "        \"bins\": bins\n",
    "    }\n",
    "\n",
    "def preprocess_all_serial(image_paths, size=(224, 224), bins=32, limit=None):\n",
    "    \"\"\"\n",
    "    Preprocess pipeline for a list of images.\n",
    "    Returns a list of dictionaries, each containing components for reuse.\n",
    "    \"\"\"\n",
    "    if limit is not None:\n",
    "        image_paths = image_paths[:limit]\n",
    "    return [preprocess_one(path, size=size, bins=bins) for path in image_paths]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f2e77",
   "metadata": {},
   "source": [
    "### Performance test on different resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388b26be",
   "metadata": {},
   "source": [
    "Default size 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a66a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 samples in 3.64 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "samples_big = preprocess_all_serial(paths, limit=None)\n",
    "elapsed = time.perf_counter() - t0\n",
    "\n",
    "print(f\"Processed {len(samples_big)} samples in {elapsed:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f7ba7",
   "metadata": {},
   "source": [
    "112x112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55be4fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 samples in 1.36 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "samples_medium = preprocess_all_serial(paths, limit=None, size=(112,112))\n",
    "elapsed = time.perf_counter() - t0\n",
    "\n",
    "print(f\"Processed {len(samples_medium)} samples in {elapsed:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c0d8c",
   "metadata": {},
   "source": [
    "56x56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1783a6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 samples in 0.93 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "samples_small = preprocess_all_serial(paths, limit=None, size=(56,56))\n",
    "elapsed = time.perf_counter() - t0\n",
    "\n",
    "print(f\"Processed {len(samples_small)} samples in {elapsed:.2f} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-parallelism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
